# -*- coding: utf-8 -*-
"""cifar100_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VVHeNzjZ_IsnA_22M_1LXz28PvohsV0M
"""

from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, BatchNormalization
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.regularizers import l1, l2
from keras.callbacks import EarlyStopping


def cifar100_model(num_classes):
  earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')
  model = Sequential()
  weight_decay = 0.0005

  model.add(Conv2D(64, (3, 3), input_shape=(3, 32, 32), padding='same', activation='relu', kernel_regularizer=l2(weight_decay)))
  model.add(BatchNormalization())
  model.add(Dropout(0.3))
  model.add(Conv2D(64, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))
  model.add(BatchNormalization())
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Conv2D(128, (3, 3), padding='same', activation='relu',kernel_regularizer=l2(weight_decay)))
  model.add(BatchNormalization())
  model.add(Dropout(0.4))
  model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
  model.add(BatchNormalization())
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Conv2D(256, (3, 3), padding='same', activation='relu',kernel_regularizer=l2(weight_decay)))
  model.add(BatchNormalization())
  model.add(Dropout(0.4))
  model.add(Conv2D(256, (3, 3), padding='same', activation='relu',kernel_regularizer=l2(weight_decay)))
  model.add(BatchNormalization())
  model.add(Dropout(0.4))
  model.add(Conv2D(256, (3, 3), padding='same', activation='relu',kernel_regularizer=l2(weight_decay)))
  model.add(BatchNormalization())
  model.add(MaxPooling2D(pool_size=(2, 2)))

  model.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))
  model.add(BatchNormalization()) 
  model.add(Dropout(0.4))
  model.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))
  model.add(BatchNormalization())
  model.add(Dropout(0.4))
  model.add(Conv2D(512, (3, 3), activation='relu', padding='same',kernel_regularizer=l2(weight_decay)))
  model.add(BatchNormalization())
  model.add(MaxPooling2D(pool_size=(2, 2)))
          
  model.add(Dropout(0.5))
  model.add(Flatten())
  model.add(Dense(512, activation='relu',kernel_regularizer=l2(weight_decay)))
  model.add(BatchNormalization())
          
  model.add(Dropout(0.5))
  model.add(Dense(num_classes, activation='softmax'))
  return model